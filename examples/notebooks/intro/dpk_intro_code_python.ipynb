{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbF_Zw3KBazf"
   },
   "source": [
    "# **Demo on building data prep pipeline for model fine tuning** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/IBM/data-prep-kit/blob/tree/dev/examples/notebooks/code/sample-notebook.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-NOkuTxiP7r",
    "outputId": "043f32fc-c476-433e-86b6-d7e9abd4d285"
   },
   "source": [
    "This notebook demonstrates data preparation techniques for fine-tuning language models using the Data Prep Kit.\n",
    "Here is the workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add pipeline image here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run this notebook\n",
    "\n",
    "Two options:\n",
    "\n",
    "- **Option 1 - Google Colab:** easiest option.  no setup required.  Click this link to open this on google colab.  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IBM/data-prep-kit/blob/dev/examples/notebooks/cods-demo.ipynb)\n",
    "- **Option 2 - Local python dev environment:**  Setup using this [guide](../../../README.md#-getting-started)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: SET UP\n",
    "\n",
    "### 1.1 - Determine runtime\n",
    "\n",
    "Determine if we are running on Google colab or local python environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT in Colab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   print(\"Running in Colab\")\n",
    "   RUNNING_IN_COLAB = True\n",
    "else:\n",
    "   print(\"NOT in Colab\")\n",
    "   RUNNING_IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 -Download Data if running on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-14 00:03:46--  https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/input/application-java.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28680721 (27M) [application/zip]\n",
      "Saving to: ‘input/source-code-data/application-java.zip’\n",
      "\n",
      "input/source-code-d 100%[===================>]  27.35M  7.79MB/s    in 3.5s    \n",
      "\n",
      "2024-12-14 00:03:50 (7.80 MB/s) - ‘input/source-code-data/application-java.zip’ saved [28680721/28680721]\n",
      "\n",
      "--2024-12-14 00:03:50--  https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/input/data-processing-lib.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118377 (116K) [application/zip]\n",
      "Saving to: ‘input/source-code-data/data-processing-lib.zip’\n",
      "\n",
      "input/source-code-d 100%[===================>] 115.60K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-12-14 00:03:50 (4.46 MB/s) - ‘input/source-code-data/data-processing-lib.zip’ saved [118377/118377]\n",
      "\n",
      "--2024-12-14 00:03:51--  https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/input/https___github.com_00000o1_environments_archive_refs_heads_master.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "connected. to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... \n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 5086554 (4.9M) [application/zip]\n",
      "Saving to: ‘input/source-code-data/https___github.com_00000o1_environments_archive_refs_heads_master.zip’\n",
      "\n",
      "input/source-code-d 100%[===================>]   4.85M  8.87MB/s    in 0.5s    \n",
      "\n",
      "2024-12-14 00:03:52 (8.87 MB/s) - ‘input/source-code-data/https___github.com_00000o1_environments_archive_refs_heads_master.zip’ saved [5086554/5086554]\n",
      "\n",
      "--2024-12-14 00:03:52--  https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/intro/my_utils.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1856 (1.8K) [text/plain]\n",
      "Saving to: ‘my_utils.py’\n",
      "\n",
      "my_utils.py         100%[===================>]   1.81K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-12-14 00:03:53 (1.29 MB/s) - ‘my_utils.py’ saved [1856/1856]\n",
      "\n",
      "--2024-12-14 00:03:53--  https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/languages/lang_extensions.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "15544 (15K) [text/plain]\n",
      "Saving to: ‘language.json’\n",
      "\n",
      "language.json       100%[===================>]  15.18K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-12-14 00:03:53 (19.2 MB/s) - ‘language.json’ saved [15544/15544]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RUNNING_IN_COLAB = True\n",
    "if RUNNING_IN_COLAB:\n",
    "    !mkdir -p 'input/source-code-data'\n",
    "\n",
    "    !wget -O 'input/source-code-data/application-java.zip'  'https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/input/application-java.zip'\n",
    "    !wget -O 'input/source-code-data/data-processing-lib.zip' 'https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/input/data-processing-lib.zip'\n",
    "    !wget -O 'input/source-code-data/https___github.com_00000o1_environments_archive_refs_heads_master.zip' 'https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/input/https___github.com_00000o1_environments_archive_refs_heads_master.zip'\n",
    "    !wget -O 'my_utils.py'  'https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/intro/my_utils.py'\n",
    "    !wget -O 'language.json'  'https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/test-data/languages/lang_extensions.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Install dependencies if running on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: data-prep-toolkit-transforms==0.2.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.2.2)\n",
      "Requirement already satisfied: data-prep-toolkit>=0.2.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2) (0.2.2)\n",
      "Requirement already satisfied: bs4==0.0.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.0.2)\n",
      "Requirement already satisfied: transformers==4.38.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (4.38.2)\n",
      "Requirement already satisfied: parameterized in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.9.0)\n",
      "Requirement already satisfied: pandas in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (2.2.2)\n",
      "Requirement already satisfied: docling-core==2.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (2.3.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.0.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (2.9.2)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.22 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.11.23)\n",
      "Requirement already satisfied: fasttext==0.9.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.9.2)\n",
      "Requirement already satisfied: langcodes==3.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.21.4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.26.5)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (1.26.4)\n",
      "Requirement already satisfied: sentence-transformers==3.0.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (3.0.1)\n",
      "Requirement already satisfied: docling-ibm-models==2.0.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (2.0.3)\n",
      "Requirement already satisfied: deepsearch-glm==0.26.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.26.1)\n",
      "Requirement already satisfied: docling==2.3.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (2.3.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (1.2.0)\n",
      "Requirement already satisfied: nltk==3.9.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (3.9.1)\n",
      "Requirement already satisfied: torch<=2.4.1,>=2.2.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (2.4.1)\n",
      "Requirement already satisfied: mmh3>=4.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (4.1.0)\n",
      "Requirement already satisfied: xxhash==3.4.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (3.4.1)\n",
      "Requirement already satisfied: duckdb>=0.10.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (1.1.3)\n",
      "Requirement already satisfied: data_prep_connector>=0.2.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit-transforms[all]==0.2.2) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from bs4==0.0.2->data-prep-toolkit-transforms[all]==0.2.2) (4.12.3)\n",
      "Requirement already satisfied: pyarrow==16.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit>=0.2.2->data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2) (16.1.0)\n",
      "Requirement already satisfied: boto3==1.34.69 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit>=0.2.2->data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2) (1.34.69)\n",
      "Collecting argparse (from data-prep-toolkit>=0.2.2->data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: psutil in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data-prep-toolkit>=0.2.2->data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2) (6.1.0)\n",
      "Requirement already satisfied: docutils!=0.21 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (0.21.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (13.9.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (4.67.1)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (2024.8.30)\n",
      "Requirement already satisfied: docling-parse<3.0.0,>=2.0.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (2.1.2)\n",
      "Requirement already satisfied: easyocr<2.0,>=1.7 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.7.2)\n",
      "Requirement already satisfied: marko<3.0.0,>=2.1.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (2.1.2)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (2.7.0)\n",
      "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (4.30.0)\n",
      "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.1.2)\n",
      "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.0.2)\n",
      "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.3.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.14.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.14.1)\n",
      "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (0.12.5)\n",
      "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-core==2.3.0->data-prep-toolkit-transforms[all]==0.2.2) (1.1.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-core==2.3.0->data-prep-toolkit-transforms[all]==0.2.2) (4.23.0)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-core==2.3.0->data-prep-toolkit-transforms[all]==0.2.2) (10.4.0)\n",
      "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-ibm-models==2.0.3->data-prep-toolkit-transforms[all]==0.2.2) (3.1.0)\n",
      "Requirement already satisfied: lxml<5.0.0,>=4.9.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-ibm-models==2.0.3->data-prep-toolkit-transforms[all]==0.2.2) (4.9.4)\n",
      "Requirement already satisfied: mean_average_precision<2022.0.0.0,>=2021.4.26.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-ibm-models==2.0.3->data-prep-toolkit-transforms[all]==0.2.2) (2021.4.26.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-ibm-models==2.0.3->data-prep-toolkit-transforms[all]==0.2.2) (4.10.0.84)\n",
      "Requirement already satisfied: torchvision<1,>=0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from docling-ibm-models==2.0.3->data-prep-toolkit-transforms[all]==0.2.2) (0.19.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from fasttext==0.9.2->data-prep-toolkit-transforms[all]==0.2.2) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from fasttext==0.9.2->data-prep-toolkit-transforms[all]==0.2.2) (75.5.0)\n",
      "Requirement already satisfied: click in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from nltk==3.9.1->data-prep-toolkit-transforms[all]==0.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from nltk==3.9.1->data-prep-toolkit-transforms[all]==0.2.2) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from nltk==3.9.1->data-prep-toolkit-transforms[all]==0.2.2) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas->data-prep-toolkit-transforms[all]==0.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas->data-prep-toolkit-transforms[all]==0.2.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas->data-prep-toolkit-transforms[all]==0.2.2) (2024.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from sentence-transformers==3.0.1->data-prep-toolkit-transforms[all]==0.2.2) (1.6.0)\n",
      "Requirement already satisfied: filelock in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from transformers==4.38.2->data-prep-toolkit-transforms[all]==0.2.2) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from transformers==4.38.2->data-prep-toolkit-transforms[all]==0.2.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from transformers==4.38.2->data-prep-toolkit-transforms[all]==0.2.2) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from transformers==4.38.2->data-prep-toolkit-transforms[all]==0.2.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from transformers==4.38.2->data-prep-toolkit-transforms[all]==0.2.2) (0.4.5)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.69 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from boto3==1.34.69->data-prep-toolkit>=0.2.2->data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from boto3==1.34.69->data-prep-toolkit>=0.2.2->data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from boto3==1.34.69->data-prep-toolkit>=0.2.2->data-prep-toolkit-transforms==0.2.2->data-prep-toolkit-transforms[all]==0.2.2) (0.10.4)\n",
      "Requirement already satisfied: scrapy>=2.11.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (2.12.0)\n",
      "Requirement already satisfied: tldextract>=5.1.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (5.1.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.21.4->data-prep-toolkit-transforms[all]==0.2.2) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.21.4->data-prep-toolkit-transforms[all]==0.2.2) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.0.8)\n",
      "Requirement already satisfied: httpx in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (3.4.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.17.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.0.0->data-prep-toolkit-transforms[all]==0.2.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.0.0->data-prep-toolkit-transforms[all]==0.2.2) (2.23.4)\n",
      "Requirement already satisfied: sympy in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from torch<=2.4.1,>=2.2.2->data-prep-toolkit-transforms[all]==0.2.2) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from torch<=2.4.1,>=2.2.2->data-prep-toolkit-transforms[all]==0.2.2) (3.1.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from beautifulsoup4->bs4==0.0.2->data-prep-toolkit-transforms[all]==0.2.2) (2.6)\n",
      "Requirement already satisfied: scikit-image in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (0.6.3)\n",
      "Requirement already satisfied: Shapely in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.11.1.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core==2.3.0->data-prep-toolkit-transforms[all]==0.2.2) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core==2.3.0->data-prep-toolkit-transforms[all]==0.2.2) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core==2.3.0->data-prep-toolkit-transforms[all]==0.2.2) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->data-prep-toolkit-transforms[all]==0.2.2) (1.17.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from python-pptx<2.0.0,>=1.0.2->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (2.18.0)\n",
      "Requirement already satisfied: Twisted>=21.7.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (24.11.0)\n",
      "Requirement already satisfied: cryptography>=37.0.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (44.0.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (1.3.2)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (1.9.1)\n",
      "Requirement already satisfied: pyOpenSSL>=22.0.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (24.3.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (1.7.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (24.2.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (2.2.1)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (7.2)\n",
      "Requirement already satisfied: protego>=0.1.15 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (0.3.1)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (0.10.0)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (0.7.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (3.1.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from tldextract>=5.1.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (2.1.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from typer<0.13.0,>=0.12.5->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (3.23.1)\n",
      "Requirement already satisfied: anyio in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from jinja2->torch<=2.4.1,>=2.2.2->data-prep-toolkit-transforms[all]==0.2.2) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==3.0.1->data-prep-toolkit-transforms[all]==0.2.2) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from sympy->torch<=2.4.1,>=2.2.2->data-prep-toolkit-transforms[all]==0.2.2) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from cryptography>=37.0.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (1.17.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->deepsearch-glm==0.26.1->data-prep-toolkit-transforms[all]==0.2.2) (0.1.2)\n",
      "Requirement already satisfied: pyasn1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (0.4.1)\n",
      "Requirement already satisfied: automat>=24.8.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from Twisted>=21.7.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (24.8.1)\n",
      "Requirement already satisfied: constantly>=15.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from Twisted>=21.7.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from Twisted>=21.7.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (21.0.0)\n",
      "Requirement already satisfied: incremental>=24.7.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from Twisted>=21.7.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (24.7.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.22->data-prep-toolkit-transforms[all]==0.2.2) (1.3.1)\n",
      "Requirement already satisfied: imageio>=2.33 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (2.36.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (2024.12.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling==2.3.1->data-prep-toolkit-transforms[all]==0.2.2) (0.4)\n",
      "Requirement already satisfied: pycparser in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy>=2.11.2->data_prep_connector>=0.2.3->data-prep-toolkit-transforms[all]==0.2.2) (2.22)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Requirement already satisfied: datasets in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (0.26.5)\n",
      "Requirement already satisfied: packaging in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: pandas in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: humanfriendly in /Users/sapthasurendran/.pyenv/versions/3.11.2/envs/nb3/lib/python3.11/site-packages (10.0)\n"
     ]
    }
   ],
   "source": [
    "RUNNING_IN_COLAB = True\n",
    "if RUNNING_IN_COLAB:\n",
    "    !pip install \"data-prep-toolkit-transforms[all]==0.2.2\"\n",
    "    !pip install datasets\n",
    "    !pip install pandas\n",
    "    !pip install humanfriendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Restart Runtime\n",
    "\n",
    "After installing dependencies, be sure <font color=\"red\">restart runtime</font>, so libraries will be loaded\n",
    "\n",
    "You do this by going to **`Runtime --> Restart Session`**\n",
    "\n",
    "Then you can continue to the next step (no need to re-run the notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Configure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2.1: Basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT in Colab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   print(\"Running in Colab\")\n",
    "   RUNNING_IN_COLAB = True\n",
    "else:\n",
    "   print(\"NOT in Colab\")\n",
    "   RUNNING_IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## Configuration\n",
    "class MyConfig:\n",
    "    pass\n",
    "\n",
    "MY_CONFIG = MyConfig ()\n",
    "\n",
    "MY_CONFIG.INPUT_DATA_DIR = 'input/source-code-data/'\n",
    "\n",
    "MY_CONFIG.OUTPUT_FOLDER = \"output\"\n",
    "MY_CONFIG.OUTPUT_FOLDER_FINAL = os.path.join(MY_CONFIG.OUTPUT_FOLDER , \"output_final\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add parent dir to path\n",
    "import os,sys\n",
    "\n",
    "this_dir = os.path.abspath('')\n",
    "parent_dir = os.path.dirname(this_dir)\n",
    "sys.path.append (os.path.abspath (parent_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Setup input/outpur directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleared output directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.exists(MY_CONFIG.INPUT_DATA_DIR ):\n",
    "    raise Exception (f\"❌ Input folder MY_CONFIG.INPUT_DATA_DIR = '{MY_CONFIG.INPUT_DATA_DIR}' not found\")\n",
    "\n",
    "output_parquet_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '01_parquet_out')\n",
    "\n",
    "output_exact_dedupe_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '02_exact_dedupe_out')\n",
    "output_code_quality_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '03_code_quality_out')\n",
    "output_filter_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '04_filter_out')\n",
    "output_tokenisation_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '05_tokenisation_out')\n",
    "\n",
    "## clear output folder\n",
    "shutil.rmtree(MY_CONFIG.OUTPUT_FOLDER, ignore_errors=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print (\"✅ Cleared output directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xliMSdQEEwYx"
   },
   "source": [
    "## Step-3: Data ingestion -  Convert source data to Parquet\n",
    "\n",
    "\n",
    "This is the first component of this pipeline. It ingests few zip files and converts it into\n",
    "parquet files for consumption by the next steps in this data processing pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add image - describe data transformation - multiple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-1: Processing input='input/source-code-data/' --> output='output/01_parquet_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE = 1\n",
    "\n",
    "input_folder = MY_CONFIG.INPUT_DATA_DIR\n",
    "output_folder =  output_parquet_dir\n",
    "\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:05:35 INFO - data factory code2parquet_ is using local configuration without input/output path\n",
      "00:05:35 INFO - data factory code2parquet_ max_files -1, n_sample -1\n",
      "00:05:35 INFO - data factory code2parquet_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "00:05:35 INFO - pipeline id pipeline_id\n",
      "00:05:35 INFO - code location None\n",
      "00:05:35 INFO - data factory data_ is using local data access: input_folder - input/source-code-data/ output_folder - output/01_parquet_out\n",
      "00:05:35 INFO - data factory data_ max_files -1, n_sample -1\n",
      "00:05:35 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.zip'], files to checkpoint ['.parquet']\n",
      "00:05:35 INFO - orchestrator code2parquet started at 2024-12-14 00:05:35\n",
      "00:05:35 INFO - Number of files is 3, source profile {'max_file_size': 27.35206699371338, 'min_file_size': 0.11289310455322266, 'total_file_size': 32.31587600708008}\n",
      "00:05:35 WARNING - file application-java/lib/application-java.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/fabric-gateway-java-2.1.1.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/fabric-sdk-java-2.1.1.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/grpc-protobuf-1.23.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/protobuf-java-util-3.10.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/api-common-1.9.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/milagro-crypto-java-0.4.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/grpc-stub-1.23.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/grpc-netty-1.23.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/grpc-core-1.23.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/grpc-protobuf-lite-1.23.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/grpc-api-1.23.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/guava-29.0-jre.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/failureaccess-1.0.1.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/perfmark-api-0.17.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/jsr305-3.0.2.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/checker-qual-2.11.1.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/error_prone_annotations-2.3.4.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/j2objc-annotations-1.3.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/cloudant-client-2.19.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-tcnative-boringssl-static-2.0.30.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-codec-http2-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/protobuf-java-3.10.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/bcpkix-jdk15on-1.62.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/httpclient-4.5.12.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/commons-logging-1.2.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/commons-cli-1.4.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/commons-compress-1.20.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/cloudant-http-2.19.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/commons-io-2.6.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/apache-log4j-extras-1.2.17.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/log4j-1.2.17.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/futures-extra-4.2.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/javax.json-1.1.4.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/snakeyaml-1.26.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/jaxb-api-2.3.1.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/javax.annotation-api-1.3.2.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/gson-2.8.5.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/commons-codec-1.11.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-handler-proxy-4.1.38.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/proto-google-common-protos-1.12.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-codec-http-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-handler-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-codec-socks-4.1.38.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-codec-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-transport-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-buffer-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-resolver-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/netty-common-4.1.49.Final.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/bcprov-jdk15on-1.62.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/httpcore-4.4.13.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/auto-value-annotations-1.7.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/commons-math3-3.6.1.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/javax.activation-api-1.2.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/annotations-4.1.1.4.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/opencensus-contrib-grpc-metrics-0.21.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/opencensus-api-0.21.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/grpc-context-1.23.0.jar is empty. content , skipping\n",
      "00:05:35 WARNING - file application-java/lib/animal-sniffer-annotations-1.17.jar is empty. content , skipping\n",
      "00:05:35 INFO - Completed 1 files (33.33%) in 0.005 min\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/daf/input/ds1/sample2.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/daf/input/ds1/sample1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/daf/input/ds2/sample3.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/daf/output/ds1/sample1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/input/sample1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/ray/noop/input/subdir/test1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/ray/noop/input/sample1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/ray/noop/expected/subdir/test1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/ray/noop/expected/sample1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/input_multiple/sample2.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/input_multiple/sample3.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/test-data/data_processing/input_multiple/sample1.parquet is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/src/data_processing_ray/test_support/__init__.py is empty. content , skipping\n",
      "00:05:35 WARNING - file ray/data-processing-lib.zip is empty. content , skipping\n",
      "00:05:35 INFO - Completed 2 files (66.67%) in 0.005 min\n",
      "00:05:35 WARNING - file environments-master/cfortunes/diebenkorn_notes.dat is empty. content , skipping\n",
      "00:05:35 WARNING - file environments-master/cfortunes/obliquestrategies.dat is empty. content , skipping\n",
      "00:05:35 WARNING - file environments-master/commands/grel is empty. content , skipping\n",
      "00:05:35 WARNING - file environments-master/commands/ldid is empty. content , skipping\n",
      "00:05:35 INFO - Completed 3 files (100.0%) in 0.006 min\n",
      "00:05:35 INFO - Done processing 3 files, waiting for flush() completion.\n",
      "00:05:35 INFO - done flushing in 0.0 sec\n",
      "00:05:35 INFO - Completed execution in 0.006 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:1 completed successfully\n",
      "CPU times: user 1.5 s, sys: 1.29 s, total: 2.79 s\n",
      "Wall time: 606 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "import sys\n",
    "import ast\n",
    "from data_processing.utils import ParamsUtils\n",
    "from data_processing.runtime.pure_python import PythonTransformLauncher\n",
    "from code2parquet_transform import (  # domain_key,; snapshot_key,\n",
    "    detect_programming_lang_cli_key,\n",
    "    supported_langs_file_cli_key,\n",
    ")\n",
    "from code2parquet_transform_python import CodeToParquetPythonConfiguration\n",
    "# Prepare the commandline params\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "\n",
    "\n",
    "supported_languages_file = \"language.json\"\n",
    "\n",
    "params = {\n",
    "\n",
    "\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "\n",
    "    # code2parquet parameters\n",
    "    supported_langs_file_cli_key: supported_languages_file,\n",
    "    detect_programming_lang_cli_key: True,\n",
    "    \"data_files_to_use\": ast.literal_eval(\"['.zip']\"),\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf)\n",
    "}\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "# create launcher\n",
    "launcher = PythonTransformLauncher(CodeToParquetPythonConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"❌ Ray job failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/01_parquet_out'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Inspect Generated output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensions (rows x columns)=  (74, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>document</th>\n",
       "      <th>contents</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>programming_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application-java/bin/application-java</td>\n",
       "      <td>application-java.zip</td>\n",
       "      <td>#!/usr/bin/env sh\\n\\n#\\n# Copyright 2015 the o...</td>\n",
       "      <td>cadbcc7e-4a0b-4115-a5b5-ad325b8d2194</td>\n",
       "      <td></td>\n",
       "      <td>318066feeb8ac614dd5eab57fbf2faa5a83f2b582a089f...</td>\n",
       "      <td>8168</td>\n",
       "      <td>2024-12-14T00:05:35.272041</td>\n",
       "      <td>application-java</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application-java/bin/application-java.bat</td>\n",
       "      <td>application-java.zip</td>\n",
       "      <td>@rem\\r\\n@rem Copyright 2015 the original autho...</td>\n",
       "      <td>5d338050-f7ed-4f52-95aa-da4b905fa60c</td>\n",
       "      <td>.bat</td>\n",
       "      <td>e90dc018527e3b0798537919c4e49fb2b25ebec62aa7a9...</td>\n",
       "      <td>5539</td>\n",
       "      <td>2024-12-14T00:05:35.272261</td>\n",
       "      <td>application-java</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray/.gitignore</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td>\\n\\n\\n# Byte-compiled / optimized / DLL files\\...</td>\n",
       "      <td>899c061b-27a0-4b22-af03-4e2712f1f6df</td>\n",
       "      <td></td>\n",
       "      <td>10d9872967cc070881e20d8691a6461abc148fad6543e0...</td>\n",
       "      <td>357</td>\n",
       "      <td>2024-12-14T00:05:35.428454</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>238d4a07-3758-4368-944b-1e549a02cde8</td>\n",
       "      <td>.py</td>\n",
       "      <td>8a768e1ed38b458e121928f15a0d782d2f9d4ee39e4f65...</td>\n",
       "      <td>2828</td>\n",
       "      <td>2024-12-14T00:05:35.428699</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>faf3b1fa-51b4-407d-b70c-e6796e35735e</td>\n",
       "      <td>.py</td>\n",
       "      <td>5a2a60c8e23fffc0956595760b0b532d85b21dd36db8d5...</td>\n",
       "      <td>1853</td>\n",
       "      <td>2024-12-14T00:05:35.428746</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 document  \\\n",
       "0              application-java/bin/application-java     application-java.zip   \n",
       "1          application-java/bin/application-java.bat     application-java.zip   \n",
       "2                                     ray/.gitignore  data-processing-lib.zip   \n",
       "3  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "4  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "\n",
       "                                            contents  \\\n",
       "0  #!/usr/bin/env sh\\n\\n#\\n# Copyright 2015 the o...   \n",
       "1  @rem\\r\\n@rem Copyright 2015 the original autho...   \n",
       "2  \\n\\n\\n# Byte-compiled / optimized / DLL files\\...   \n",
       "3  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "4  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "\n",
       "                            document_id   ext  \\\n",
       "0  cadbcc7e-4a0b-4115-a5b5-ad325b8d2194         \n",
       "1  5d338050-f7ed-4f52-95aa-da4b905fa60c  .bat   \n",
       "2  899c061b-27a0-4b22-af03-4e2712f1f6df         \n",
       "3  238d4a07-3758-4368-944b-1e549a02cde8   .py   \n",
       "4  faf3b1fa-51b4-407d-b70c-e6796e35735e   .py   \n",
       "\n",
       "                                                hash  size  \\\n",
       "0  318066feeb8ac614dd5eab57fbf2faa5a83f2b582a089f...  8168   \n",
       "1  e90dc018527e3b0798537919c4e49fb2b25ebec62aa7a9...  5539   \n",
       "2  10d9872967cc070881e20d8691a6461abc148fad6543e0...   357   \n",
       "3  8a768e1ed38b458e121928f15a0d782d2f9d4ee39e4f65...  2828   \n",
       "4  5a2a60c8e23fffc0956595760b0b532d85b21dd36db8d5...  1853   \n",
       "\n",
       "                date_acquired            repo_name programming_language  \n",
       "0  2024-12-14T00:05:35.272041     application-java              unknown  \n",
       "1  2024-12-14T00:05:35.272261     application-java            Batchfile  \n",
       "2  2024-12-14T00:05:35.428454  data-processing-lib              unknown  \n",
       "3  2024-12-14T00:05:35.428699  data-processing-lib               Python  \n",
       "4  2024-12-14T00:05:35.428746  data-processing-lib               Python  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Output dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(5)\n",
    "\n",
    "## To display certain columns\n",
    "#parquet_df[['column1', 'column2', 'column3']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Understand the output\n",
    "\n",
    "Here are some interesting attributes to note:\n",
    "\n",
    "- **filename** : original filename\n",
    "- **contents** : text\n",
    "- **document_id**: unique id (UUID) assignd to this document\n",
    "- **hash** : hash of document\n",
    "- **pdf_convert_time** : time to convert this pdf in seconds\n",
    "\n",
    "Let's inspect the **contents** column.  See how the text is being divided up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "\n",
    "pprint.pprint (json.loads(output_df.iloc[0, ]['contents']))\n",
    "# json.loads(output_df.iloc[0, ]['contents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 - Metadata information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mread_metadata\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/metadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_metadata' is not defined"
     ]
    }
   ],
   "source": [
    "read_metadata(f\"{output_folder}/metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step-4: Exact Deduplication\n",
    "\n",
    "This step will find exact duplicates in the 'content' column and remove them. This is done by computing SHA256 hash on the code files and remove records having identical hashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-2: Processing input='output/01_parquet_out' --> output='output/02_exact_dedupe_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE = 2\n",
    "\n",
    "input_folder = output_parquet_dir # previous output folder is the input folder for the current stage\n",
    "output_folder =  output_exact_dedupe_dir\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:13:14 INFO - exact dedup params are {'doc_column': 'contents', 'doc_id_column': 'document_id', 'use_snapshot': False, 'snapshot_directory': None}\n",
      "00:13:14 INFO - pipeline id pipeline_id\n",
      "00:13:14 INFO - code location None\n",
      "00:13:14 INFO - data factory data_ is using local data access: input_folder - output/01_parquet_out output_folder - output/02_exact_dedupe_out\n",
      "00:13:14 INFO - data factory data_ max_files -1, n_sample -1\n",
      "00:13:14 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "00:13:14 INFO - orchestrator ededup started at 2024-12-14 00:13:14\n",
      "00:13:14 INFO - Number of files is 3, source profile {'max_file_size': 0.03529071807861328, 'min_file_size': 0.00879669189453125, 'total_file_size': 0.06692790985107422}\n",
      "00:13:14 INFO - Starting from the beginning\n",
      "00:13:14 INFO - Completed 1 files (33.33%) in 0.0 min\n",
      "00:13:14 INFO - Completed 2 files (66.67%) in 0.0 min\n",
      "00:13:14 INFO - Completed 3 files (100.0%) in 0.0 min\n",
      "00:13:14 INFO - Done processing 3 files, waiting for flush() completion.\n",
      "00:13:14 INFO - done flushing in 0.0 sec\n",
      "00:13:14 INFO - Completed execution in 0.0 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:2 completed successfully\n",
      "CPU times: user 25.2 ms, sys: 9.9 ms, total: 35.1 ms\n",
      "Wall time: 26.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "\n",
    "from ededup_transform_python import EdedupPythonTransformRuntimeConfiguration\n",
    "from ededup_transform_base import doc_column_name_cli_param, int_column_name_cli_param\n",
    "\n",
    "from data_processing.utils import ParamsUtils\n",
    "\n",
    "# Prepare the commandline params\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # ededup parameters\n",
    "    doc_column_name_cli_param: \"contents\",\n",
    "    int_column_name_cli_param: \"document_id\",\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf)\n",
    "}\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "# create launcher\n",
    "launcher = PythonTransformLauncher(EdedupPythonTransformRuntimeConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"❌ Ray job failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Inspect Generated output\n",
    "\n",
    "\n",
    "\n",
    "You will notice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions (rows x columns)=  (74, 10)\n",
      "Output data dimensions (rows x columns)=  (73, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>document</th>\n",
       "      <th>contents</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application-java/bin/application-java</td>\n",
       "      <td>application-java.zip</td>\n",
       "      <td>#!/usr/bin/env sh\\n\\n#\\n# Copyright 2015 the o...</td>\n",
       "      <td>cadbcc7e-4a0b-4115-a5b5-ad325b8d2194</td>\n",
       "      <td></td>\n",
       "      <td>318066feeb8ac614dd5eab57fbf2faa5a83f2b582a089f...</td>\n",
       "      <td>8168</td>\n",
       "      <td>2024-12-14T00:05:35.272041</td>\n",
       "      <td>application-java</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application-java/bin/application-java.bat</td>\n",
       "      <td>application-java.zip</td>\n",
       "      <td>@rem\\r\\n@rem Copyright 2015 the original autho...</td>\n",
       "      <td>5d338050-f7ed-4f52-95aa-da4b905fa60c</td>\n",
       "      <td>.bat</td>\n",
       "      <td>e90dc018527e3b0798537919c4e49fb2b25ebec62aa7a9...</td>\n",
       "      <td>5539</td>\n",
       "      <td>2024-12-14T00:05:35.272261</td>\n",
       "      <td>application-java</td>\n",
       "      <td>Batchfile</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray/.gitignore</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td>\\n\\n\\n# Byte-compiled / optimized / DLL files\\...</td>\n",
       "      <td>899c061b-27a0-4b22-af03-4e2712f1f6df</td>\n",
       "      <td></td>\n",
       "      <td>10d9872967cc070881e20d8691a6461abc148fad6543e0...</td>\n",
       "      <td>357</td>\n",
       "      <td>2024-12-14T00:05:35.428454</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>238d4a07-3758-4368-944b-1e549a02cde8</td>\n",
       "      <td>.py</td>\n",
       "      <td>8a768e1ed38b458e121928f15a0d782d2f9d4ee39e4f65...</td>\n",
       "      <td>2828</td>\n",
       "      <td>2024-12-14T00:05:35.428699</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>faf3b1fa-51b4-407d-b70c-e6796e35735e</td>\n",
       "      <td>.py</td>\n",
       "      <td>5a2a60c8e23fffc0956595760b0b532d85b21dd36db8d5...</td>\n",
       "      <td>1853</td>\n",
       "      <td>2024-12-14T00:05:35.428746</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>d1b948b6-29e9-4eda-9b43-97b943c95b0e</td>\n",
       "      <td>.py</td>\n",
       "      <td>0d48720a35061d1085ac040f2a96cb57ae82d3921edfdd...</td>\n",
       "      <td>7229</td>\n",
       "      <td>2024-12-14T00:05:35.428786</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>66008011-5ee1-4620-bedd-be3c39b53169</td>\n",
       "      <td>.py</td>\n",
       "      <td>62286fd87e04cd78dc419854778ef4d98f7bdb2b8cf515...</td>\n",
       "      <td>3292</td>\n",
       "      <td>2024-12-14T00:05:35.428818</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ray/pyproject.toml</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td>[project]\\nname = \"data_prep_toolkit_ray\"\\nver...</td>\n",
       "      <td>2b6fd286-c370-47c6-aed1-80018ad85681</td>\n",
       "      <td>.toml</td>\n",
       "      <td>6b2df4f160514a3f43fa81dec6c59da01bb2faa62d72dc...</td>\n",
       "      <td>1337</td>\n",
       "      <td>2024-12-14T00:05:35.428843</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>TOML</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ray/test-data/data_processing/ray/noop/expecte...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td>{\\n    \"pipeline\": \"pipeline_id\",\\n    \"job de...</td>\n",
       "      <td>9b2210d2-7031-4875-ba80-8996571a588a</td>\n",
       "      <td>.json</td>\n",
       "      <td>317541c784bbf90c260f9f74ca31957afbcaf8c4adb66e...</td>\n",
       "      <td>1128</td>\n",
       "      <td>2024-12-14T00:05:35.430952</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>JSON</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ray/Makefile</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># Use make help, to see the available rules\\nR...</td>\n",
       "      <td>891081b4-69c0-443a-a0fe-543fb7cdb1ec</td>\n",
       "      <td></td>\n",
       "      <td>784fc2ccbc718411372a6f45d0405ff4b36da89f56bcd8...</td>\n",
       "      <td>1766</td>\n",
       "      <td>2024-12-14T00:05:35.432188</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 document  \\\n",
       "0              application-java/bin/application-java     application-java.zip   \n",
       "1          application-java/bin/application-java.bat     application-java.zip   \n",
       "2                                     ray/.gitignore  data-processing-lib.zip   \n",
       "3  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "4  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "5  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "6  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "7                                 ray/pyproject.toml  data-processing-lib.zip   \n",
       "8  ray/test-data/data_processing/ray/noop/expecte...  data-processing-lib.zip   \n",
       "9                                       ray/Makefile  data-processing-lib.zip   \n",
       "\n",
       "                                            contents  \\\n",
       "0  #!/usr/bin/env sh\\n\\n#\\n# Copyright 2015 the o...   \n",
       "1  @rem\\r\\n@rem Copyright 2015 the original autho...   \n",
       "2  \\n\\n\\n# Byte-compiled / optimized / DLL files\\...   \n",
       "3  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "4  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "5  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "6  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "7  [project]\\nname = \"data_prep_toolkit_ray\"\\nver...   \n",
       "8  {\\n    \"pipeline\": \"pipeline_id\",\\n    \"job de...   \n",
       "9  # Use make help, to see the available rules\\nR...   \n",
       "\n",
       "                            document_id    ext  \\\n",
       "0  cadbcc7e-4a0b-4115-a5b5-ad325b8d2194          \n",
       "1  5d338050-f7ed-4f52-95aa-da4b905fa60c   .bat   \n",
       "2  899c061b-27a0-4b22-af03-4e2712f1f6df          \n",
       "3  238d4a07-3758-4368-944b-1e549a02cde8    .py   \n",
       "4  faf3b1fa-51b4-407d-b70c-e6796e35735e    .py   \n",
       "5  d1b948b6-29e9-4eda-9b43-97b943c95b0e    .py   \n",
       "6  66008011-5ee1-4620-bedd-be3c39b53169    .py   \n",
       "7  2b6fd286-c370-47c6-aed1-80018ad85681  .toml   \n",
       "8  9b2210d2-7031-4875-ba80-8996571a588a  .json   \n",
       "9  891081b4-69c0-443a-a0fe-543fb7cdb1ec          \n",
       "\n",
       "                                                hash  size  \\\n",
       "0  318066feeb8ac614dd5eab57fbf2faa5a83f2b582a089f...  8168   \n",
       "1  e90dc018527e3b0798537919c4e49fb2b25ebec62aa7a9...  5539   \n",
       "2  10d9872967cc070881e20d8691a6461abc148fad6543e0...   357   \n",
       "3  8a768e1ed38b458e121928f15a0d782d2f9d4ee39e4f65...  2828   \n",
       "4  5a2a60c8e23fffc0956595760b0b532d85b21dd36db8d5...  1853   \n",
       "5  0d48720a35061d1085ac040f2a96cb57ae82d3921edfdd...  7229   \n",
       "6  62286fd87e04cd78dc419854778ef4d98f7bdb2b8cf515...  3292   \n",
       "7  6b2df4f160514a3f43fa81dec6c59da01bb2faa62d72dc...  1337   \n",
       "8  317541c784bbf90c260f9f74ca31957afbcaf8c4adb66e...  1128   \n",
       "9  784fc2ccbc718411372a6f45d0405ff4b36da89f56bcd8...  1766   \n",
       "\n",
       "                date_acquired            repo_name programming_language  \\\n",
       "0  2024-12-14T00:05:35.272041     application-java              unknown   \n",
       "1  2024-12-14T00:05:35.272261     application-java            Batchfile   \n",
       "2  2024-12-14T00:05:35.428454  data-processing-lib              unknown   \n",
       "3  2024-12-14T00:05:35.428699  data-processing-lib               Python   \n",
       "4  2024-12-14T00:05:35.428746  data-processing-lib               Python   \n",
       "5  2024-12-14T00:05:35.428786  data-processing-lib               Python   \n",
       "6  2024-12-14T00:05:35.428818  data-processing-lib               Python   \n",
       "7  2024-12-14T00:05:35.428843  data-processing-lib                 TOML   \n",
       "8  2024-12-14T00:05:35.430952  data-processing-lib                 JSON   \n",
       "9  2024-12-14T00:05:35.432188  data-processing-lib              unknown   \n",
       "\n",
       "  removed  \n",
       "0      []  \n",
       "1      []  \n",
       "2      []  \n",
       "3      []  \n",
       "4      []  \n",
       "5      []  \n",
       "6      []  \n",
       "7      []  \n",
       "8      []  \n",
       "9      []  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step-5: Code Quality\n",
    "\n",
    "Code quality gives detailed evaluation of various aspects of code quality in your dataset, offering metrics to analyze structural properties, detect anomalies, and classify files based on their characteristics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-3: Processing input='output/02_exact_dedupe_out' --> output='output/03_code_quality_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE = 3\n",
    "\n",
    "input_folder = output_exact_dedupe_dir # previous output folder is the input folder for the current stage\n",
    "output_folder =  output_code_quality_dir\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:36 INFO - pipeline id pipeline_id\n",
      "00:24:36 INFO - code location None\n",
      "00:24:36 INFO - data factory data_ is using local data access: input_folder - output/02_exact_dedupe_out output_folder - output/03_code_quality_out\n",
      "00:24:36 INFO - data factory data_ max_files -1, n_sample -1\n",
      "00:24:36 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "00:24:36 INFO - orchestrator code_quality started at 2024-12-14 00:24:36\n",
      "00:24:36 INFO - Number of files is 3, source profile {'max_file_size': 0.035880088806152344, 'min_file_size': 0.009145736694335938, 'total_file_size': 0.0682210922241211}\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "00:24:36 INFO - Completed 1 files (33.33%) in 0.0 min\n",
      "00:24:36 INFO - Completed 2 files (66.67%) in 0.001 min\n",
      "00:24:36 INFO - Completed 3 files (100.0%) in 0.001 min\n",
      "00:24:36 INFO - Done processing 3 files, waiting for flush() completion.\n",
      "00:24:36 INFO - done flushing in 0.0 sec\n",
      "00:24:36 INFO - Completed execution in 0.006 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:3 completed successfully\n",
      "CPU times: user 150 ms, sys: 17.7 ms, total: 167 ms\n",
      "Wall time: 392 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "import sys\n",
    "from code_quality_transform_python import CodeQualityPythonTransformConfiguration\n",
    "from data_processing.utils import ParamsUtils\n",
    "\n",
    "\n",
    "# Prepare the commandline params\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # code quality parameters\n",
    "    \"cq_contents_column_name\": \"contents\",\n",
    "    \"cq_language_column_name\": \"programming_language\",\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf)\n",
    "}\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "# create launcher\n",
    "launcher = PythonTransformLauncher(CodeQualityPythonTransformConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"❌ Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Inspect Generated output\n",
    "\n",
    "\n",
    "\n",
    "You will notice we have two extra columns\n",
    "\n",
    "\n",
    "\n",
    "- **line_mean**: Average line length.\n",
    "- **line_max**: Longest line length.\n",
    "- **total_num_lines**: Number of lines.\n",
    "- **avg_longest_lines**: Avg. of top n longest lines.\n",
    "- **alphanum_frac**: Alphanumeric fraction.\n",
    "- **char_token_ratio**: Character-to-token ratio.\n",
    "- **autogenerated**: Detects autogenerated files.\n",
    "- **config_or_test**: Identifies config/test files.\n",
    "- **has_no_keywords**: No Python keywords (e.g., class, def).\n",
    "- **has_few_assignments**: Fewer than min = signs.\n",
    "- **is_xml/is_html**: Detects XML or HTML content.\n",
    "\n",
    "\n",
    "But still the same number or rows as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions (rows x columns)=  (73, 11)\n",
      "Output data dimensions (rows x columns)=  (73, 23)\n",
      "Index(['title', 'document', 'contents', 'document_id', 'ext', 'hash', 'size',\n",
      "       'date_acquired', 'repo_name', 'programming_language', 'removed',\n",
      "       'line_mean', 'line_max', 'total_num_lines', 'avg_longest_lines',\n",
      "       'alphanum_frac', 'char_token_ratio', 'autogenerated', 'config_or_test',\n",
      "       'has_no_keywords', 'has_few_assignments', 'is_xml', 'is_html'],\n",
      "      dtype='object')\n",
      "('-------Total Num Lines 3------\\n'\n",
      " 'from .noop_transform import (\\n'\n",
      " '    NOOPRayTransformConfiguration,\\n'\n",
      " ')\\n'\n",
      " '\\n'\n",
      " '-------')\n",
      "('-------Total Num Lines 8------\\n'\n",
      " 'from data_processing_ray.runtime.ray.ray_utils import RayUtils\\n'\n",
      " 'from data_processing_ray.runtime.ray.transform_statistics import '\n",
      " 'TransformStatisticsRay\\n'\n",
      " 'from data_processing_ray.runtime.ray.transform_runtime import '\n",
      " 'DefaultRayTransformRuntime\\n'\n",
      " 'from data_processing_ray.runtime.ray.runtime_configuration import '\n",
      " 'RayTransformRuntimeConfiguration\\n'\n",
      " 'from data_processing_ray.runtime.ray.transform_file_processor import '\n",
      " 'RayTransformFileProcessor\\n'\n",
      " 'from data_processing_ray.runtime.ray.execution_configuration import '\n",
      " 'RayTransformExecutionConfiguration\\n'\n",
      " 'from data_processing_ray.runtime.ray.transform_orchestrator import '\n",
      " 'orchestrate\\n'\n",
      " 'from data_processing_ray.runtime.ray.transform_launcher import '\n",
      " 'RayTransformLauncher\\n'\n",
      " '\\n'\n",
      " '-------')\n",
      "('-------Total Num Lines 5------\\n'\n",
      " 'function gdrive_download () {\\n'\n",
      " '  CONFIRM=$(wget --quiet --save-cookies /tmp/cookies.txt '\n",
      " '--keep-session-cookies --no-check-certificate '\n",
      " '\"https://docs.google.com/uc?export=download&id=$1\" -O- | sed -rn '\n",
      " \"'s/.*confirm=([0-9A-Za-z_]+).*/\\\\1\\\\n/p')\\n\"\n",
      " '  wget --load-cookies /tmp/cookies.txt '\n",
      " '\"https://docs.google.com/uc?export=download&confirm=$CONFIRM&id=$1\" -O $2\\n'\n",
      " '  rm -rf /tmp/cookies.txt\\n'\n",
      " '}\\n'\n",
      " '\\n'\n",
      " '-------')\n"
     ]
    }
   ],
   "source": [
    "from my_utils import read_parquet_files_as_df\n",
    "import pprint\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(10)\n",
    "\n",
    "pprint.pprint(output_df.columns)\n",
    "total_num_lines_rows=output_df[output_df[\"total_num_lines\"]<10].head(3)\n",
    "\n",
    "for _, row in total_num_lines_rows.iterrows():  # Use the second element (row) from the tuple\n",
    "    pprint.pprint(f'-------Total Num Lines {row[\"total_num_lines\"]}------\\n{row[\"contents\"]}\\n-------')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXu_i9jLAo9H"
   },
   "source": [
    "##  Step-6: Filtering\n",
    " \n",
    "This step can be used to filter the code files based on our chosen conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 - Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-4: Processing input='output/03_code_quality_out' --> output='output/04_filter_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE = 4\n",
    "\n",
    "input_folder = output_code_quality_dir # previous output folder is the input folder for the current stage\n",
    "output_folder =  output_filter_dir\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAl7B58oAyZQ",
    "outputId": "5fc229ef-bb87-4e34-9302-1670b8832d97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:05:37 INFO - pipeline id pipeline_id\n",
      "01:05:37 INFO - code location None\n",
      "01:05:37 INFO - data factory data_ is using local data access: input_folder - output/03_code_quality_out output_folder - output/04_filter_out\n",
      "01:05:37 INFO - data factory data_ max_files -1, n_sample -1\n",
      "01:05:37 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "01:05:37 INFO - orchestrator filter started at 2024-12-14 01:05:37\n",
      "01:05:37 INFO - Number of files is 3, source profile {'max_file_size': 0.041484832763671875, 'min_file_size': 0.013142585754394531, 'total_file_size': 0.08251476287841797}\n",
      "01:05:37 INFO - Completed 1 files (33.33%) in 0.0 min\n",
      "01:05:37 INFO - Completed 2 files (66.67%) in 0.001 min\n",
      "01:05:37 INFO - Completed 3 files (100.0%) in 0.001 min\n",
      "01:05:37 INFO - Done processing 3 files, waiting for flush() completion.\n",
      "01:05:37 INFO - done flushing in 0.0 sec\n",
      "01:05:37 INFO - Completed execution in 0.001 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:4 completed successfully\n",
      "CPU times: user 46.4 ms, sys: 32.7 ms, total: 79.2 ms\n",
      "Wall time: 55.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "from filter_transform import (\n",
    "    filter_columns_to_drop_cli_param,\n",
    "    filter_criteria_cli_param,\n",
    "    filter_logical_operator_cli_param,\n",
    ")\n",
    "from filter_transform_python import FilterPythonTransformConfiguration\n",
    "from data_processing.utils import ParamsUtils\n",
    "\n",
    "\n",
    "\n",
    "# Prepare the commandline params\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "\n",
    "filter_criteria = [\n",
    "    \"total_num_lines > 10 AND total_num_lines < 90\"\n",
    "]\n",
    "filter_logical_operator = \"AND\"\n",
    "filter_columns_to_drop = [\"removed\"]\n",
    "\n",
    "params = {\n",
    "\n",
    "    # filter parameters\n",
    "    filter_criteria_cli_param: filter_criteria,\n",
    "    filter_columns_to_drop_cli_param: filter_columns_to_drop,\n",
    "    filter_logical_operator_cli_param: filter_logical_operator,\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf)\n",
    "}\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "# create launcher\n",
    "launcher = PythonTransformLauncher(FilterPythonTransformConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"❌ Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 - Inspect Generated output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : 73\n",
      "Rows created : 33\n",
      "Input data dimensions (rows x columns)=  (73, 23)\n",
      "Output data dimensions (rows x columns)=  (33, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>document</th>\n",
       "      <th>contents</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>...</th>\n",
       "      <th>total_num_lines</th>\n",
       "      <th>avg_longest_lines</th>\n",
       "      <th>alphanum_frac</th>\n",
       "      <th>char_token_ratio</th>\n",
       "      <th>autogenerated</th>\n",
       "      <th>config_or_test</th>\n",
       "      <th>has_no_keywords</th>\n",
       "      <th>has_few_assignments</th>\n",
       "      <th>is_xml</th>\n",
       "      <th>is_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ray/.gitignore</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td>\\n\\n\\n# Byte-compiled / optimized / DLL files\\...</td>\n",
       "      <td>899c061b-27a0-4b22-af03-4e2712f1f6df</td>\n",
       "      <td></td>\n",
       "      <td>10d9872967cc070881e20d8691a6461abc148fad6543e0...</td>\n",
       "      <td>357</td>\n",
       "      <td>2024-12-14T00:05:35.428454</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>238d4a07-3758-4368-944b-1e549a02cde8</td>\n",
       "      <td>.py</td>\n",
       "      <td>8a768e1ed38b458e121928f15a0d782d2f9d4ee39e4f65...</td>\n",
       "      <td>2828</td>\n",
       "      <td>2024-12-14T00:05:35.428699</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>79.571429</td>\n",
       "      <td>0.649222</td>\n",
       "      <td>3.677503</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray/test/data_processing_ray_tests/launch/ray/...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>faf3b1fa-51b4-407d-b70c-e6796e35735e</td>\n",
       "      <td>.py</td>\n",
       "      <td>5a2a60c8e23fffc0956595760b0b532d85b21dd36db8d5...</td>\n",
       "      <td>1853</td>\n",
       "      <td>2024-12-14T00:05:35.428746</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>91.857143</td>\n",
       "      <td>0.693470</td>\n",
       "      <td>4.010823</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ray/pyproject.toml</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td>[project]\\nname = \"data_prep_toolkit_ray\"\\nver...</td>\n",
       "      <td>2b6fd286-c370-47c6-aed1-80018ad85681</td>\n",
       "      <td>.toml</td>\n",
       "      <td>6b2df4f160514a3f43fa81dec6c59da01bb2faa62d72dc...</td>\n",
       "      <td>1337</td>\n",
       "      <td>2024-12-14T00:05:35.428843</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>TOML</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>67.571429</td>\n",
       "      <td>0.635752</td>\n",
       "      <td>2.701010</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ray/test-data/data_processing/ray/noop/expecte...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td>{\\n    \"pipeline\": \"pipeline_id\",\\n    \"job de...</td>\n",
       "      <td>9b2210d2-7031-4875-ba80-8996571a588a</td>\n",
       "      <td>.json</td>\n",
       "      <td>317541c784bbf90c260f9f74ca31957afbcaf8c4adb66e...</td>\n",
       "      <td>1128</td>\n",
       "      <td>2024-12-14T00:05:35.430952</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>JSON</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>43.857143</td>\n",
       "      <td>0.454787</td>\n",
       "      <td>3.204545</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ray/Makefile</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># Use make help, to see the available rules\\nR...</td>\n",
       "      <td>891081b4-69c0-443a-a0fe-543fb7cdb1ec</td>\n",
       "      <td></td>\n",
       "      <td>784fc2ccbc718411372a6f45d0405ff4b36da89f56bcd8...</td>\n",
       "      <td>1766</td>\n",
       "      <td>2024-12-14T00:05:35.432188</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>121.714286</td>\n",
       "      <td>0.731597</td>\n",
       "      <td>3.109155</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ray/src/data_processing_ray/test_support/trans...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>c0a4c2d4-6885-45ec-9941-5206f5177603</td>\n",
       "      <td>.py</td>\n",
       "      <td>653c74f4cf6f34e6aaad5cdeb93d9599633e205e14a62a...</td>\n",
       "      <td>1580</td>\n",
       "      <td>2024-12-14T00:05:35.432308</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>76.571429</td>\n",
       "      <td>0.700633</td>\n",
       "      <td>4.463277</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ray/src/data_processing_ray/runtime/ray/transf...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>10d62504-9d44-4d81-bfa5-5600632773b7</td>\n",
       "      <td>.py</td>\n",
       "      <td>d3e6f9b32396f7336767198c1c37703e8fe9be8a830623...</td>\n",
       "      <td>2523</td>\n",
       "      <td>2024-12-14T00:05:35.432567</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>102.285714</td>\n",
       "      <td>0.690844</td>\n",
       "      <td>4.724719</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ray/src/data_processing_ray/runtime/ray/transf...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>171b95eb-f494-400d-9280-c876a0798344</td>\n",
       "      <td>.py</td>\n",
       "      <td>4710d5b4ae145bfed0a5765bce5c12dce9b66bbe8536b8...</td>\n",
       "      <td>3289</td>\n",
       "      <td>2024-12-14T00:05:35.432641</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>101.285714</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>4.414765</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ray/src/data_processing_ray/runtime/ray/transf...</td>\n",
       "      <td>data-processing-lib.zip</td>\n",
       "      <td># (C) Copyright IBM Corp. 2024.\\n# Licensed un...</td>\n",
       "      <td>979f574c-9e8f-4f8b-b156-08a09b0719de</td>\n",
       "      <td>.py</td>\n",
       "      <td>2a27ccb73d717ce53215b545521c64bd5fa83f62dd6db0...</td>\n",
       "      <td>1993</td>\n",
       "      <td>2024-12-14T00:05:35.432993</td>\n",
       "      <td>data-processing-lib</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>79.285714</td>\n",
       "      <td>0.671350</td>\n",
       "      <td>4.592166</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 document  \\\n",
       "0                                     ray/.gitignore  data-processing-lib.zip   \n",
       "1  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "2  ray/test/data_processing_ray_tests/launch/ray/...  data-processing-lib.zip   \n",
       "3                                 ray/pyproject.toml  data-processing-lib.zip   \n",
       "4  ray/test-data/data_processing/ray/noop/expecte...  data-processing-lib.zip   \n",
       "5                                       ray/Makefile  data-processing-lib.zip   \n",
       "6  ray/src/data_processing_ray/test_support/trans...  data-processing-lib.zip   \n",
       "7  ray/src/data_processing_ray/runtime/ray/transf...  data-processing-lib.zip   \n",
       "8  ray/src/data_processing_ray/runtime/ray/transf...  data-processing-lib.zip   \n",
       "9  ray/src/data_processing_ray/runtime/ray/transf...  data-processing-lib.zip   \n",
       "\n",
       "                                            contents  \\\n",
       "0  \\n\\n\\n# Byte-compiled / optimized / DLL files\\...   \n",
       "1  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "2  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "3  [project]\\nname = \"data_prep_toolkit_ray\"\\nver...   \n",
       "4  {\\n    \"pipeline\": \"pipeline_id\",\\n    \"job de...   \n",
       "5  # Use make help, to see the available rules\\nR...   \n",
       "6  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "7  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "8  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "9  # (C) Copyright IBM Corp. 2024.\\n# Licensed un...   \n",
       "\n",
       "                            document_id    ext  \\\n",
       "0  899c061b-27a0-4b22-af03-4e2712f1f6df          \n",
       "1  238d4a07-3758-4368-944b-1e549a02cde8    .py   \n",
       "2  faf3b1fa-51b4-407d-b70c-e6796e35735e    .py   \n",
       "3  2b6fd286-c370-47c6-aed1-80018ad85681  .toml   \n",
       "4  9b2210d2-7031-4875-ba80-8996571a588a  .json   \n",
       "5  891081b4-69c0-443a-a0fe-543fb7cdb1ec          \n",
       "6  c0a4c2d4-6885-45ec-9941-5206f5177603    .py   \n",
       "7  10d62504-9d44-4d81-bfa5-5600632773b7    .py   \n",
       "8  171b95eb-f494-400d-9280-c876a0798344    .py   \n",
       "9  979f574c-9e8f-4f8b-b156-08a09b0719de    .py   \n",
       "\n",
       "                                                hash  size  \\\n",
       "0  10d9872967cc070881e20d8691a6461abc148fad6543e0...   357   \n",
       "1  8a768e1ed38b458e121928f15a0d782d2f9d4ee39e4f65...  2828   \n",
       "2  5a2a60c8e23fffc0956595760b0b532d85b21dd36db8d5...  1853   \n",
       "3  6b2df4f160514a3f43fa81dec6c59da01bb2faa62d72dc...  1337   \n",
       "4  317541c784bbf90c260f9f74ca31957afbcaf8c4adb66e...  1128   \n",
       "5  784fc2ccbc718411372a6f45d0405ff4b36da89f56bcd8...  1766   \n",
       "6  653c74f4cf6f34e6aaad5cdeb93d9599633e205e14a62a...  1580   \n",
       "7  d3e6f9b32396f7336767198c1c37703e8fe9be8a830623...  2523   \n",
       "8  4710d5b4ae145bfed0a5765bce5c12dce9b66bbe8536b8...  3289   \n",
       "9  2a27ccb73d717ce53215b545521c64bd5fa83f62dd6db0...  1993   \n",
       "\n",
       "                date_acquired            repo_name programming_language  ...  \\\n",
       "0  2024-12-14T00:05:35.428454  data-processing-lib              unknown  ...   \n",
       "1  2024-12-14T00:05:35.428699  data-processing-lib               Python  ...   \n",
       "2  2024-12-14T00:05:35.428746  data-processing-lib               Python  ...   \n",
       "3  2024-12-14T00:05:35.428843  data-processing-lib                 TOML  ...   \n",
       "4  2024-12-14T00:05:35.430952  data-processing-lib                 JSON  ...   \n",
       "5  2024-12-14T00:05:35.432188  data-processing-lib              unknown  ...   \n",
       "6  2024-12-14T00:05:35.432308  data-processing-lib               Python  ...   \n",
       "7  2024-12-14T00:05:35.432567  data-processing-lib               Python  ...   \n",
       "8  2024-12-14T00:05:35.432641  data-processing-lib               Python  ...   \n",
       "9  2024-12-14T00:05:35.432993  data-processing-lib               Python  ...   \n",
       "\n",
       "   total_num_lines  avg_longest_lines  alphanum_frac  char_token_ratio  \\\n",
       "0               35          23.857143       0.714286          2.625000   \n",
       "1               80          79.571429       0.649222          3.677503   \n",
       "2               39          91.857143       0.693470          4.010823   \n",
       "3               49          67.571429       0.635752          2.701010   \n",
       "4               46          43.857143       0.454787          3.204545   \n",
       "5               49         121.714286       0.731597          3.109155   \n",
       "6               45          76.571429       0.700633          4.463277   \n",
       "7               53         102.285714       0.690844          4.724719   \n",
       "8               66         101.285714       0.622378          4.414765   \n",
       "9               46          79.285714       0.671350          4.592166   \n",
       "\n",
       "   autogenerated  config_or_test  has_no_keywords  has_few_assignments  \\\n",
       "0          False           False            False                False   \n",
       "1          False           False            False                False   \n",
       "2          False            True            False                False   \n",
       "3          False            True            False                False   \n",
       "4          False           False            False                False   \n",
       "5          False            True            False                False   \n",
       "6          False           False            False                False   \n",
       "7          False           False            False                 True   \n",
       "8          False           False            False                False   \n",
       "9          False           False            False                False   \n",
       "\n",
       "   is_xml  is_html  \n",
       "0   False    False  \n",
       "1   False    False  \n",
       "2   False    False  \n",
       "3   False    False  \n",
       "4   False    False  \n",
       "5   False    False  \n",
       "6   False    False  \n",
       "7   False    False  \n",
       "8   False    False  \n",
       "9   False    False  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (f\"Files processed : {input_df.shape[0]:,}\")\n",
    "print (f\"Rows created : {output_df.shape[0]:,}\")\n",
    "\n",
    "print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 - Metadata Information \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_metadata(f\"{output_folder}/metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byK75Kb1A3E7"
   },
   "source": [
    "##  Step-7: Tokenization\n",
    "\n",
    "Next, we tokenize the data to be used for fine tuning. \n",
    "\n",
    "Add more info...tokeniser used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Set Input/output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-5: Processing input='output/04_filter_out' --> output='output/05_tokenisation_out'\n"
     ]
    }
   ],
   "source": [
    "STAGE = 5\n",
    "\n",
    "input_folder = output_filter_dir # previous output folder is the input folder for the current stage\n",
    "output_folder =  output_tokenisation_dir\n",
    "\n",
    "input_df = read_parquet_files_as_df(input_folder)  ## for debug purposes\n",
    "\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{input_folder}' --> output='{output_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBYg93WMBBq6",
    "outputId": "b3e0541e-4a3d-46f4-8809-ccc8778a53fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:10:04 INFO - pipeline id pipeline_id\n",
      "01:10:04 INFO - code location None\n",
      "01:10:04 INFO - data factory data_ is using local data access: input_folder - output/04_filter_out output_folder - output/05_tokenisation_out\n",
      "01:10:04 INFO - data factory data_ max_files -1, n_sample -1\n",
      "01:10:04 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "01:10:04 INFO - orchestrator Tokenization started at 2024-12-14 01:10:04\n",
      "01:10:04 INFO - Number of files is 3, source profile {'max_file_size': 0.027441024780273438, 'min_file_size': 0.004353523254394531, 'total_file_size': 0.05213642120361328}\n",
      "01:10:05 WARNING - table is empty, skipping processing\n",
      "01:10:05 INFO - Completed 1 files (33.33%) in 0.0 min\n",
      "01:10:05 INFO - Completed 2 files (66.67%) in 0.0 min\n",
      "01:10:05 INFO - Completed 3 files (100.0%) in 0.0 min\n",
      "01:10:05 INFO - Done processing 3 files, waiting for flush() completion.\n",
      "01:10:05 INFO - done flushing in 0.0 sec\n",
      "01:10:05 INFO - Completed execution in 0.016 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:5 completed successfully\n",
      "CPU times: user 108 ms, sys: 25.9 ms, total: 134 ms\n",
      "Wall time: 963 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "import sys\n",
    "\n",
    "from data_processing.utils import ParamsUtils\n",
    "from tokenization_transform_python import TokenizationPythonConfiguration\n",
    "\n",
    "\n",
    "# Prepare the commandline params\n",
    "local_conf = {\n",
    "    \"input_folder\": input_folder,\n",
    "    \"output_folder\": output_folder,\n",
    "}\n",
    "\n",
    "\n",
    "params = {\n",
    "    # Data access. Only required parameters are specified\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "\n",
    "}\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "# create launcher\n",
    "launcher = PythonTransformLauncher(TokenizationPythonConfiguration())\n",
    "# launch\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"❌ Ray job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - Inspect Generated output\n",
    "\n",
    "Here we should see the contents column tokenised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_parquet_files_as_df\n\u001b[0;32m----> 3\u001b[0m output_df \u001b[38;5;241m=\u001b[39m read_parquet_files_as_df(\u001b[43moutput_folder\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput dimensions (rows x columns)= \u001b[39m\u001b[38;5;124m\"\u001b[39m, output_df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m output_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_folder' is not defined"
     ]
    }
   ],
   "source": [
    "from my_utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_folder)\n",
    "\n",
    "print (\"Output dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFUrzzjeBFfJ"
   },
   "source": [
    "**The data is now ready for extended pretraining or fine tuning using any open source code models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
